{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a83a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyproj import CRS\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from shapely import wkt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import codecs\n",
    "import osm2geojson\n",
    "from shapely import wkt\n",
    "\n",
    "import gzip\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment, tostring\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# set the working directory\n",
    "BASE_DIR = Path.cwd()\n",
    "\n",
    "# auto reloading\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc5a452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\goyal\\.virtualenvs\\overpass_turbo-zwxzihl_\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\goyal\\.virtualenvs\\overpass_turbo-zwxzihl_\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (7,14,17,26,29,30,33,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dfSWITRS = pd.read_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"CollisionRecords.txt\"))\n",
    "dfTIMSCity = pd.read_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"TIMS_Crashes_city.csv\"))\n",
    "dfTIMSStateRoutes = pd.read_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"TIMS_Crahes_StateRoutes.csv\"))\n",
    "\n",
    "# SWITRS database\n",
    "dfSWITRS = dfSWITRS[dfSWITRS[\"ACCIDENT_YEAR\"].isin([2010,2016])]\n",
    "# TIMS database\n",
    "dfTIMSCity = dfTIMSCity[dfTIMSCity[\"ACCIDENT_YEAR\"].isin([2010,2016])]\n",
    "dfTIMSStateRoutes = dfTIMSStateRoutes[dfTIMSStateRoutes[\"ACCIDENT_YEAR\"].isin([2010,2016])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc4555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dfTIMSCity,dfTIMSStateRoutes]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "\n",
    "result['POINT_X']= np.where(result['POINT_X'].isnull(), result['LONGITUDE'], result['POINT_X'])\n",
    "result['POINT_Y']= np.where(result['POINT_Y'].isnull(), result['LATITUDE'], result['POINT_Y'])\n",
    "\n",
    "result = result.drop_duplicates(subset=['CASE_ID'],keep=\"first\")\n",
    "result.to_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"TIMS_all.csv\"))\n",
    "\n",
    "frames = [result,dfSWITRS]\n",
    "result_2 = pd.concat(frames)\n",
    "result_2['POINT_X']= np.where(result_2['POINT_X'].isnull(), result_2['LONGITUDE'], result_2['POINT_X'])\n",
    "result_2['POINT_Y']= np.where(result_2['POINT_Y'].isnull(), result_2['LATITUDE'], result_2['POINT_Y'])\n",
    "\n",
    "result_2['POINT_X']= np.where(result_2['POINT_X']>0, -abs(result_2['POINT_X']), result_2['POINT_X'])\n",
    "\n",
    "result_3 = result_2.drop_duplicates(subset=['CASE_ID'])\n",
    "result_3.to_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"Switrs_TIMS_all.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99be2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b2c274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\goyal\\.virtualenvs\\overpass_turbo-zwxzihl_\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (3,5,77,78) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# read the exported file and also the actual data from SWITRS\n",
    "BASE_DIR = Path.cwd()\n",
    "dfIntersect_Rds = pd.read_csv(BASE_DIR.parent.joinpath(\"Exported_files\",\"Intersecting_Rds.csv\"))\n",
    "\n",
    "dfIntersect_Rds['geometry'] = dfIntersect_Rds['geometry'].apply(wkt.loads)\n",
    "dfIntersect_Rds = gpd.GeoDataFrame(dfIntersect_Rds, crs='epsg:4326')\n",
    "col = [\"Unnamed: 0\", \"index\",\"layer\",\"path\"]\n",
    "dfIntersect_Rds = dfIntersect_Rds.drop(col,axis=1).copy()\n",
    "\n",
    "dfSWITRS = pd.read_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"Switrs_TIMS_all.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2f26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStreetName(streetName):\n",
    "    newStreetName = streetName.strip()\n",
    "    corrections = {\"TWELFTH\":\"12TH\", \n",
    "                   \"ELEVENTH\":\"11TH\",\n",
    "                   \"TENTH\":\"10TH\",\n",
    "                   \"NINTH\":\"9TH\",\n",
    "                   \"EIGHTH\":\"8TH\",\n",
    "                   \"SEVENTH\":\"7TH\",\n",
    "                   \"SIXTH\":\"6TH\",\n",
    "                   \"FIFTH\":\"5TH\",\n",
    "                   \"FOURTH\":\"4TH\",\n",
    "                   \"THIRD\":\"3RD\",\n",
    "                   \"SECOND\":\"2ND\",\n",
    "                   \"FIRST\":\"1ST\",\n",
    "                   \"O'FARRELL\":\"O FARRELL\",\n",
    "                   \"3RDREET\":\"3RD\",\n",
    "                   \"EMBARCADERO/KING\":\"THE EMBARCADERO\",\n",
    "                   \"VAN NESSNUE\":\"VAN NESS\",\n",
    "                   \"3RD #3\":\"3RD\",\n",
    "                   \"BAYSHORE #3\":\"BAYSHORE\",\n",
    "                   \"09TH\":\"9TH\",\n",
    "                   \"08TH\":\"8TH\",\n",
    "                   \"07TH\":\"7TH\",\n",
    "                   \"06TH\":\"6TH\",\n",
    "                   \"05TH\":\"5TH\",\n",
    "                   \"04TH\":\"4TH\",\n",
    "                   \"03RD\":\"3RD\",\n",
    "                   \"02ND\":\"2ND\",\n",
    "                   \"01ST\":\"1ST\",\n",
    "                  }\n",
    "\n",
    "    itemsToRemove = [\" STREETS\",\n",
    "                     \" STS.\",\n",
    "                     \" STS\",\n",
    "                     \" ST.\",\n",
    "                     \" ST\",\n",
    "                     \" Street\",\n",
    "                     \" RD.\",\n",
    "                     \" RD\",\n",
    "                     \" Road\",\n",
    "                     \" AVE.\",\n",
    "                     \" AVES\",\n",
    "                     \" AVE\",\n",
    "                     \" AV\",\n",
    "                     \" Avenue\",\n",
    "                     \" BLVD.\",\n",
    "                     \" BLVD\",\n",
    "                     \" BL\",                     \n",
    "                     \" Boulevard\",\n",
    "                     \" MASTER:\",\n",
    "                     \" DR.\",\n",
    "                     \" Drive\",\n",
    "                     \" WY\",\n",
    "                     \" Way\",\n",
    "                     \" CT\",\n",
    "                     \" TERR\",\n",
    "                     \" Terrace\",\n",
    "                     \" HWY\"]\n",
    "          \n",
    "    for wrongName, rightName in corrections.items():\n",
    "        if wrongName in streetName:\n",
    "            newStreetName = streetName.replace(wrongName, rightName)\n",
    "        if streetName == 'EMBARCADERO':\n",
    "            newStreetName = \"THE EMBARCADERO\"\n",
    "        if streetName.endswith(\" DR\"):\n",
    "            newStreetName = streetName[:-3]\n",
    "        if streetName.endswith(\" AV\"):\n",
    "            newStreetName = streetName[:-3]\n",
    "        if \" TO \" in streetName:\n",
    "            cutOff = streetName.find(\" TO \")\n",
    "            newStreetName = streetName[:cutOff]            \n",
    "    \n",
    "    for item in itemsToRemove:\n",
    "        if item in newStreetName:\n",
    "            newStreetName = newStreetName.replace(item, \"\")\n",
    "    \n",
    "    return newStreetName.strip()\n",
    "\n",
    "\n",
    "dfSWITRS.columns = dfSWITRS.columns.str.rstrip('_x')  # strip suffix at the right end only.\n",
    "dfSWITRS[\"PRIMARY_RD_2\"] = dfSWITRS.apply(lambda x: cleanStreetName(x[\"PRIMARY_RD\"]), axis=1)\n",
    "dfSWITRS[\"SECONDARY_RD_2\"] = dfSWITRS.apply(lambda x: cleanStreetName(x[\"SECONDARY_RD\"]), axis=1)\n",
    "\n",
    "# dfSWITRS['Rd_Names'] = dfSWITRS[['PRIMARY_RD_2', 'SECONDARY_RD_2']].apply(lambda x: ' '.join(x), axis=1)\n",
    "dfSWITRS['Rd_Names'] = dfSWITRS[['PRIMARY_RD_2', 'SECONDARY_RD_2']].apply(lambda x: ','.join(set(x.unique())), axis=1)\n",
    "# remove first character from the values if it starts with \",\"\n",
    "dfSWITRS['Rd_Names'] = dfSWITRS['Rd_Names'].apply(lambda x : x[1:] if x.startswith(\",\") else x)\n",
    "# lowercase\n",
    "dfSWITRS = dfSWITRS.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "\n",
    "dfIntersect_Rds=dfIntersect_Rds.fillna(\"\").copy()\n",
    "\n",
    "dfIntersect_Rds[\"Link_ID_0_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_0\"]), axis=1)\n",
    "dfIntersect_Rds[\"Link_ID_1_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_1\"]), axis=1)\n",
    "dfIntersect_Rds[\"Link_ID_2_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_2\"]), axis=1)\n",
    "dfIntersect_Rds[\"Link_ID_3_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_3\"]), axis=1)\n",
    "dfIntersect_Rds[\"Link_ID_4_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_4\"]), axis=1)\n",
    "dfIntersect_Rds[\"Link_ID_5_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_5\"]), axis=1)\n",
    "dfIntersect_Rds[\"Link_ID_6_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_6\"]), axis=1)\n",
    "dfIntersect_Rds[\"Link_ID_7_2\"] = dfIntersect_Rds.apply(lambda x: cleanStreetName(x[\"Link_ID_7\"]), axis=1)\n",
    "\n",
    "dfIntersect_Rds['Link_Names'] = dfIntersect_Rds[['Link_ID_0_2', 'Link_ID_1_2','Link_ID_2_2', 'Link_ID_3_2','Link_ID_4_2', 'Link_ID_5_2','Link_ID_6_2', 'Link_ID_7_2']].apply(lambda x: ','.join(set(x.unique())), axis=1)\n",
    "\n",
    "# remove first character from the values if it starts with \",\"\n",
    "dfIntersect_Rds['Link_Names'] = dfIntersect_Rds['Link_Names'].apply(lambda x : x[1:] if x.startswith(\",\") else x)\n",
    "\n",
    "# lowercase\n",
    "dfIntersect_Rds = dfIntersect_Rds.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "\n",
    "dfIntersect_Rds[\"LatLong\"] = dfIntersect_Rds[\"lat\"].astype(str) + \" \" + dfIntersect_Rds[\"lon\"].astype(str)\n",
    "dfIntersect_Rds.to_csv(BASE_DIR.parent.joinpath(\"Exported_Files\",\"Intersecting_Rds_2.csv\"))\n",
    "\n",
    "# get unique street intersections and their latitude and longtitude\n",
    "dfunique = dfIntersect_Rds[['Link_Names', 'LatLong']]\n",
    "# get unique street intersections and their latitude and longtitude\n",
    "dfunique.drop_duplicates(['Link_Names'])\n",
    "mydict = dict(zip(dfunique.Link_Names, dfunique.LatLong.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e18f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "def getDerivedLatLngPosition(lat,long, dist, bearing):\n",
    "    latitude = float(lat)\n",
    "    longitude = float(long)\n",
    "    \n",
    "    DegreesToRadians = math.pi/180.0\n",
    "    RadiansToDegrees = 180.0/math.pi \n",
    "    EarthRadius = 6378137.0 # Radius of Earth in meters\n",
    "\n",
    "    latA =  latitude * DegreesToRadians\n",
    "    longA = longitude * DegreesToRadians\n",
    "    angularDistance = dist/EarthRadius\n",
    "    trueCourse = bearing * DegreesToRadians\n",
    "    \n",
    "    lat =  math.asin(math.sin(latA) * math.cos(angularDistance) + math.cos(latA) * math.sin(angularDistance) * math.cos(trueCourse))\n",
    "    \n",
    "    dlon = math.atan2(math.sin(trueCourse) * math.sin(angularDistance) * math.cos(latA), math.cos(angularDistance) - math.sin(latA) * math.sin(lat))\n",
    "    lon = ((longA + dlon + math.pi) % (math.pi*2)) - math.pi\n",
    "    \n",
    "    return Point(round(lon * RadiansToDegrees,5),round(lat * RadiansToDegrees,5))\n",
    "\n",
    "# Switcher is dictionary data type here\n",
    "def get_direction(argument):\n",
    "    switcher = {\n",
    "        \"N\": 0,\n",
    "        \"W\": -90,\n",
    "        \"E\": +90,\n",
    "        \"S\": -180\n",
    "    }  \n",
    "    # get() method of dictionary data type returns value of passed argument if it is present in dictionary;\n",
    "    # otherwise second argument will be assigned as default value of passed argument\n",
    "    return switcher.get(argument, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76da923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlongsearch(row):\n",
    "    primary_rd = row[\"PRIMARY_RD_2\"]\n",
    "    secondary_rd = row[\"SECONDARY_RD_2\"] \n",
    "    _dict = mydict.copy()\n",
    "    for key, value in _dict.items():\n",
    "        if (primary_rd in key) and (secondary_rd in key):\n",
    "            lat = value.split(\" \")[0]\n",
    "            long = value.split(\" \")[1]\n",
    "            dist = 0 if (row[\"DISTANCE\"]<= 0) else (row[\"DISTANCE\"]*0.3048/3.2808)\n",
    "#             print(row[\"DIRECTION\"])\n",
    "            bearing = get_direction(row[\"DIRECTION\"].upper())\n",
    "            return getDerivedLatLngPosition(lat,long, dist, bearing)\n",
    "    return None         \n",
    "dfSWITRS[\"DIRECTION\"]=dfSWITRS[\"DIRECTION\"].fillna('')\n",
    "dfSWITRS[\"ref_latlong\"] = dfSWITRS.apply(lambda row: latlongsearch(row), axis=1)\n",
    "\n",
    "dfSWITRS.to_csv(BASE_DIR.parent.joinpath(\"Exported_Files\",\"Road_Crashes_SWITRS_TIMS_matched_output.csv\"))\n",
    "dfSWITRS.to_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"Road_Crashes_SWITRS_TIMS_matched_output.csv\"))\n",
    "\n",
    "def fill_null_latlong(row):\n",
    "    if pd.isnull(row[\"ref_latlong\"]):\n",
    "        if pd.notna(row[\"POINT_X\"]):\n",
    "            return Point(round(row[\"POINT_X\"],5),round(row[\"POINT_Y\"],5))\n",
    "    else:\n",
    "        return row[\"ref_latlong\"]\n",
    "dfSWITRS[\"ref_latlong\"] = dfSWITRS.apply(lambda row: fill_null_latlong(row), axis=1)\n",
    "\n",
    "dfSWITRS.to_csv(BASE_DIR.parent.joinpath(\"Data\",\"02Oct2021\",\"Road_Crashes_SWITRS_TIMS_matched_output_v2.csv\"))\n",
    "dfSWITRS.to_csv(BASE_DIR.parent.joinpath(\"Exported_Files\",\"Road_Crashes_SWITRS_TIMS_matched_output.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58066a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### for more detailed and split analysis please refer to 00.1 - SWITRS.ipynb file ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 2010 file\n",
    "dfSFRd = gpd.read_file(BASE_DIR.parent.joinpath(\"Data\",\"san-francisco_california.geojsonl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
